<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>New Venture Design - Sanjana's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Header -->
					<header id="header">
						<div class="inner">
							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>
								<!-- Nav -->
						</div>
					</header>

				<!-- Menu -->
				<nav id="menu">
					<h2>Menu</h2>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="coop1.html">Coop1</a></li>
						<li><a href="coop2.html">Coop2</a></li>
						<li><a href="davinci.html">DaVinci</a></li>
						<li><a href="pottery.html">Simulating Pottery</a></li>
						<li><a href="newventure.html">New Venture Design</a></li>
					</ul>
				</nav>

				<!-- Main -->
				<div id="main">
					<div class="inner">

					<!-- Header -->
					<header>
						<h1>New Venture Design</h1>
						<p style="font-size: 1.35em; color: #666; font-weight: 500;">Pouch: AI Baby Monitor for Early Developmental Disease Detection</p>
					</header>						<!-- Image -->
							<section class="tiles">
								<article class="style4 no-overlay">
								<span class="image">
									<img src="images/pouch_image.png" alt="New Venture Design" />
								</span>
							</article>
						</section>

					<!-- Content -->
					<article>
						<!-- Project Introduction -->
							<section style="background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); padding: 40px; border-radius: 8px; margin-bottom: 40px;">
								<h2 style="color: #1a3a52; font-size: 1.8em; line-height: 1.4; margin-bottom: 20px;">Project Overview</h2>
								<p style="font-size: 1.05em; line-height: 1.8; color: #333; margin-bottom: 15px;"><strong>Challenge:</strong> Cerebral palsy (CP) describes a group of permanent disorders of movement and posture caused by non-progressive disturbances that occurred in the developing fetal or infant brain. Estimates of CP prevalence vary by country and methodology; many public-health sources report prevalence in the range of approximately <strong>1‚Äì3 per 1,000 live births</strong>. Early movement differences can be subtle and are often missed by untrained observers.</p>
								
								<p style="font-size: 1.05em; line-height: 1.8; color: #333; margin-bottom: 15px;"><strong>Why early detection matters:</strong> Earlier identification allows earlier access to evidence-based interventions (for example, physiotherapy and developmental therapies), which can improve functional outcomes. Clinical tools such as the <strong>General Movements Assessment (GMA)</strong> are validated for early screening but require specialized training and are not available at scale.</p>
								
								<p style="font-size: 1.05em; line-height: 1.8; color: #333;"><strong>Solution:</strong> Pouch is an AI-powered baby monitor designed to automate validated movement assessments from routine video. By applying machine learning to pose and movement data, the system aims to provide scalable screening and earlier referral to clinicians, complementing (not replacing) clinical assessment and judgment.</p>
								
								<p style="font-size: 0.95em; color: #666; margin-top: 12px;"><strong>Sources:</strong> World Health Organization (WHO); Centers for Disease Control and Prevention (CDC); Public Health Agency of Canada; General Movements Trust (GMA overview).</p>
							</section>
						
						<div style="display: flex; gap: 30px; margin: 40px 0; flex-wrap: wrap;">
							<figure style="flex: 0 1 300px; text-align: center;">
								<img src="images/image32.png" alt="Technical Report Cover - Pouch AI Baby Monitor" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
							</figure>
							<figure style="flex: 0 1 300px; text-align: center;">
								<img src="images/image13.png" alt="Project Documentation" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
							</figure>
						</div>
						
						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #007bff; padding-bottom: 15px; margin-bottom: 30px;">Product Brief</h2>
							<div style="display: flex; gap: 20px; margin-bottom: 30px; flex-wrap: wrap;">
								<figure style="flex: 0 1 250px; text-align: center;">
									<img src="images/image3.png" alt="Product Brief Overview" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
								</figure>
								<figure style="flex: 0 1 250px; text-align: center;">
									<img src="images/image8.png" alt="Product Concept Diagram" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
								</figure>
							</div>
							
							<div style="font-size: 1.05em; line-height: 1.8;">
								<p><strong style="color: #007bff; font-size: 1.15em;">What is it?</strong> Pouch is a baby monitor that tracks an infant's growth and development from 1-24 months and identifies early signs of cerebral palsy (CP) and seizures. It consists of a camera mounted to a bassinet or crib and a companion mobile app.</p>
								
								<p><strong style="color: #007bff; font-size: 1.15em;">What will it do?</strong> The monitor will be installed on a crib and will track the infant's movements in real-time. Pouch then will flag early signs of cerebral palsy and autism so that infants can get immediate diagnosis confirmation from a physician. It will also track infant growth, monitor sleep patterns, and provide temperature tracking.</p>
								
								<p><strong style="color: #007bff; font-size: 1.15em;">How does it work?</strong> Early markers of cerebral palsy in babies are called <em>cramped synchronized general movements (CSGM)</em>‚Äîrigid, spasmodic movements that most parents might interpret as normal infant activity, but which trained medical professionals recognize as potential warning signs. Our AI model is trained on medical-quality videos of these characteristic movements to automatically identify them with high accuracy.</p>
								
								<p><strong style="color: #007bff; font-size: 1.15em;">Who is it for?</strong> Pouch is designed for parents of newborns and infants (0-24 months) seeking proactive health monitoring. Installation is simple‚Äîno technical expertise required‚Äîmaking it accessible to any family.</p>
								
								<p><strong style="color: #007bff; font-size: 1.15em;">What makes it different?</strong> Pouch would be the <strong>first device globally</strong> to automatically screen for cerebral palsy and developmental disorders. While other baby monitors focus on sleep, crying, and temperature, Pouch adds critical medical diagnostic capability‚Äîtransforming routine monitoring into early intervention.</p>
							</div>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #28a745; padding-bottom: 15px; margin-bottom: 30px;">Medical Context & Requirements</h2>
							
							<div style="background: #f0f4f8; padding: 25px; border-left: 4px solid #28a745; border-radius: 4px; margin-bottom: 30px;">
								<h3 style="color: #1a3a52; margin-top: 0; font-size: 1.3em; line-height: 1.4;">The Clinical Challenge</h3>
								<p style="font-size: 1.05em; line-height: 1.8;"><strong>Cerebral palsy</strong> is a condition affecting movement and balance. It is the most common motor disability in childhood, affecting approximately <strong>1 in 345 Canadians</strong>. Most importantly, <strong>brain plasticity is highest in the first 1-2 years of life</strong>, making early diagnosis critical for intervention success.</p>
								
								<p style="font-size: 1.05em; line-height: 1.8;"><strong>Early symptoms appear as early as 9 weeks old</strong> and manifest as specific movement patterns‚Äîcramped synchronized general movements and absent fidgety movements. However, these signs are subtle and often missed by untrained observers. Currently, the average diagnosis age is <strong>18 months</strong>, potentially months after the optimal intervention window has begun to close.</p>
								
								<p style="font-size: 1.05em; line-height: 1.8; color: #d9534f;"><strong>The difference between diagnosis at 9 weeks vs. 18 months can mean the difference between a child who walks independently and a child who requires a wheelchair for life.</strong></p>
							</div>
							
							<h3 style="font-size: 1.3em; line-height: 1.4; color: #28a745; margin-top: 30px; margin-bottom: 15px;">Our Solution Approach</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">The <strong>General Movement Assessment (GMA)</strong> is the gold-standard diagnostic test for cerebral palsy screening, but requires specialized medical training. We are automating this assessment using AI‚Äîmaking expert-level screening accessible to every family, every day, 24/7.</p>

							<h3 style="font-size: 1.3em; line-height: 1.4; color: #1a3a52; margin-top: 25px; margin-bottom: 15px;">Problem Statement</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">Signs of cerebral palsy in infants are often undiagnosed, as these characteristic movements are not obvious to parents and few doctors are trained in the General Movement Assessment. Infants are then only brought to the doctor later in their life, when parents realize that their child is not meeting important developmental milestones such as walking and sitting. As a consequence, the average age of diagnosis for cerebral palsy is 18 months. Diagnosis at this age compared to diagnosis and treatment when symptoms first start showing up at 9 weeks can make the difference between a person with cerebral palsy being able to walk versus them needing to use a wheelchair or walker for the rest of their life.</p>

							<h3 style="font-size: 1.3em; line-height: 1.4; color: #1a3a52; margin-top: 25px; margin-bottom: 15px;">Our Solution</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">There is a need for a more widely available diagnostic tool to detect early signs of cerebral palsy and other developmental diseases. We are developing the first baby monitor that detects signs of cerebral palsy, and hope to eventually expand to autism and infantile seizure detection. Our baby monitor will have all the functional aspects of a regular baby monitor such as recording baby video, sleep monitoring and cry detection, while detecting cramped synchronized movements and absent fidgety movements.</p>
							
							<p style="font-size: 1.05em; line-height: 1.8;">We have developed an LSTM model that detects signs of cerebral palsy with 71% specificity and sensitivity. This is a proof of concept that shows that given more data, we can reach our 90% target.</p>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #007bff; padding-bottom: 15px; margin-bottom: 30px;">Design Overview & Technical Architecture</h2>
							
							<h3 style="font-size: 1.3em; line-height: 1.4; color: #0056b3; margin-top: 30px; margin-bottom: 15px;">Product Architecture</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">Our system follows a modular pipeline architecture: <strong>video capture ‚Üí pose tracking ‚Üí feature selection ‚Üí ML classification ‚Üí clinical assessment</strong>. This design ensures modularity, allowing each component to be improved independently as our models advance.</p>
							<figure style="text-align: center; margin: 30px 0;">
								<img src="images/image30.png" alt="High-level Product Architecture Diagram" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
								<figcaption><strong>Figure 1:</strong> High-level design showing data collection, pose tracking, and LSTM model components.</figcaption>
							</figure>
							
							<p style="font-size: 1.05em; line-height: 1.8;">Our design has <strong>three main components:</strong></p>
							<ol style="font-size: 1.05em; line-height: 1.8;">
								<li>Data collection and labeling from infant videos</li>
								<li>Pose tracking using MediaPipe for movement capture</li>
								<li>LSTM neural network to classify normal vs. abnormal movements</li>
							</ol>
							
							<h3 style="font-size: 1.3em; line-height: 1.4; color: #0056b3; margin-top: 30px; margin-bottom: 15px;">Pose Tracking Quality Control</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">During development, we performed extensive quality control on pose tracking accuracy. Below are examples of poorly tracked poses (left) versus well-tracked poses (right):</p>
							<div class="row" style="display: flex; gap: 10px; margin: 20px 0;">
								<figure style="flex: 1;">
									<img src="images/image28.png" alt="Example of poorly tracked infant pose" />
									<figcaption><strong>Bad Tracking:</strong> Poor pose detection quality</figcaption>
								</figure>
								<figure style="flex: 1;">
									<img src="images/image23.png" alt="Example of well-tracked infant pose" />
									<figcaption><strong>Good Tracking:</strong> High-quality pose detection</figcaption>
								</figure>
							</div>

							<h3 style="font-size: 1.3em; line-height: 1.4; color: #0056b3; margin-top: 30px; margin-bottom: 15px;">Key Technologies & Model Selection</h3>
							<dl style="margin: 20px 0;">
								<dt style="font-size: 1.15em; font-weight: bold; color: #007bff; margin-top: 20px; margin-bottom: 10px;">üéØ Pose Tracking: MediaPipe</dt>
								<dd style="font-size: 1.05em; line-height: 1.8; margin-left: 20px; margin-bottom: 20px;">We selected <strong>MediaPipe</strong> for pose estimation because it performed significantly better on low-resolution videos compared to OpenPose and Movenet. This was critical for infant monitoring where camera quality may be limited. Below are comparisons of pose tracking quality across different models:
									<div class="row" style="display: flex; gap: 10px; margin: 20px 0;">
										<figure style="flex: 1;">
											<img src="images/image21.png" alt="OpenPose limb tracking on test baby video" />
											<figcaption><strong>a)</strong> OpenPose - Right leg is badly tracked</figcaption>
										</figure>
										<figure style="flex: 1;">
											<img src="images/image27.png" alt="MediaPipe limb tracking on same video" />
											<figcaption><strong>b)</strong> MediaPipe - All limbs properly tracked</figcaption>
										</figure>
										<figure style="flex: 1;">
											<img src="images/image2.png" alt="MediaPipe on challenging video" />
											<figcaption><strong>c)</strong> MediaPipe - Example of tracking failure on difficult angles</figcaption>
										</figure>
									</div>
								</dd>
								
								<dt style="font-size: 1.15em; font-weight: bold; color: #007bff; margin-top: 20px; margin-bottom: 10px;">üß† Machine Learning: LSTM Networks</dt>
								<dd style="font-size: 1.05em; line-height: 1.8; margin-left: 20px; margin-bottom: 20px;">We implemented <strong>Long Short-Term Memory (LSTM) networks</strong> to classify movement patterns from sequential pose data. The model was trained on a limited dataset of infant videos labeled by medical professionals, achieving <strong>71% specificity and sensitivity</strong> as a proof-of-concept. This demonstrates that with more training data, we can reach our target of 90% accuracy.</dd>
								
								<dt style="font-size: 1.15em; font-weight: bold; color: #007bff; margin-top: 20px; margin-bottom: 10px;">‚öôÔ∏è Data Processing Pipeline</dt>
								<dd style="font-size: 1.05em; line-height: 1.8; margin-left: 20px; margin-bottom: 20px;">We perform <strong>feature selection on 6 key limbs</strong> (left/right wrist, foot, and elbow) to reduce overfitting and improve model efficiency. MediaPipe provides 33 landmark points on the infant's body:
									<figure style="text-align: center; margin: 25px 0;">
										<img src="images/image14.png" alt="MediaPipe 33 landmark points for pose estimation" style="max-width: 400px; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption><strong>Figure 4:</strong> Pose estimation landmark points from MediaPipe</figcaption>
									</figure>
									
									<p style="font-size: 1.05em; line-height: 1.8;"><strong>Processing Steps:</strong> Videos are segmented into <strong>10-second clips</strong> and normalized before being fed to the model:</p>
									<ol style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
										<li>Raw coordinate extraction from video frames</li>
										<li>Low-pass filtering to remove noise</li>
										<li>Normalization for LSTM input</li>
									</ol>
									
									<p style="font-size: 1.05em; line-height: 1.8;"><strong>Data Transformation Example:</strong> Here's how we transform a cerebral palsy positive infant's movement data:</p>
									<div class="row" style="display: flex; gap: 10px; margin: 20px 0; flex-wrap: wrap;">
										<figure style="flex: 1; min-width: 180px; text-align: center;">
											<img src="images/image15.png" alt="Raw coordinate data showing noise" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
											<figcaption><strong>Raw Data:</strong> Left/right feet and wrist coordinates</figcaption>
										</figure>
										<figure style="flex: 1; min-width: 180px; text-align: center;">
											<img src="images/image29.png" alt="Filtered data with noise removed" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
											<figcaption><strong>Filtered:</strong> After low-pass filtering</figcaption>
										</figure>
										<figure style="flex: 1; min-width: 180px; text-align: center;">
											<img src="images/image4.png" alt="Normalized data ready for LSTM" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
											<figcaption><strong>Normalized:</strong> Ready for model input</figcaption>
										</figure>
									</div>
									
									<p style="font-size: 1.05em; line-height: 1.8; margin-top: 20px;"><strong>Feature Analysis:</strong> Comparing cerebral palsy positive (CP+) vs. negative (CP-) infants:</p>
									<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin: 30px 0;">
										<div>
											<h5 style="font-size: 1.15em; color: #dc3545; margin-bottom: 15px; text-align: center;">CP+ Infants (Cerebral Palsy Signs)</h5>
											<div style="display: flex; flex-direction: column; gap: 15px;">
												<figure style="text-align: center; margin: 0;">
													<img src="images/image4.png" alt="CP+ movement data 1" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
												<figure style="text-align: center; margin: 0;">
													<img src="images/image11.png" alt="CP+ movement data 2" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
												<figure style="text-align: center; margin: 0;">
													<img src="images/image16.png" alt="CP+ movement data 3" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
											</div>
										</div>
										<div>
											<h5 style="font-size: 1.15em; color: #28a745; margin-bottom: 15px; text-align: center;">CP- Infants (Normal Movement)</h5>
											<div style="display: flex; flex-direction: column; gap: 15px;">
												<figure style="text-align: center; margin: 0;">
													<img src="images/image25.png" alt="CP- movement data 1" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
												<figure style="text-align: center; margin: 0;">
													<img src="images/image9.png" alt="CP- movement data 2" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
												<figure style="text-align: center; margin: 0;">
													<img src="images/image22.png" alt="CP- movement data 3" style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
												</figure>
											</div>
										</div>
									</div>
									
									<p style="font-size: 1.05em; line-height: 1.8;"><strong style="color: #007bff; font-size: 1.05em;">Key Distinguishing Features:</strong></p>
									<ul style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
										<li><strong>Larger movements</strong> are characteristic in CP+ infants</li>
										<li><strong>Greater synchronicity</strong> between left and right limbs in CP+ cases</li>
										<li>Left/right wrists and feet move together synchronously in CP+ (abnormal pattern)</li>
									</ul>
								</dd>
							</dl>

						<section style="margin-top: 40px;">
							<h3 style="font-size: 1.3em; line-height: 1.4; color: #0056b3; margin-bottom: 15px;">Hardware Prototype Implementation</h3>
							<p style="font-size: 1.05em; line-height: 1.8;">We developed a hardware prototype using a <strong>Jetson Nano 4GB developer kit</strong> with an <strong>infrared camera</strong> for low-light detection capability. The live detection pipeline achieves <strong>7-14 frames per second</strong> on standard laptops, making real-time monitoring feasible for home use.</p>
							<figure style="text-align: center; margin: 30px 0;">
								<img src="images/image12.png" alt="MediaPipe tracking with Jetson Nano infrared camera" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
								<figcaption><strong>Figure 6:</strong> MediaPipe pose tracking with Jetson Nano IR camera for low-light infant monitoring</figcaption>
							</figure>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #28a745; padding-bottom: 15px; margin-bottom: 30px;">Verification & Validation Results</h2>
							
						<h3 style="font-size: 1.3em; line-height: 1.4; color: #28a745; margin-top: 30px; margin-bottom: 15px;">Clinical Model Performance (Leave-5-Out Validation)</h3>
						<p style="font-size: 1.05em; line-height: 1.8;">We used a <strong>leave-5-out cross-validation</strong> approach on 52 infant videos (26 normal, 26 cerebral palsy) to validate our LSTM model:</p>
						<div style="background: #f0f4f8; padding: 20px; border-left: 4px solid #28a745; border-radius: 4px; margin: 20px 0;">
							<ul style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
									<li><strong>Average Training Accuracy:</strong> 93.4%</li>
									<li><strong>Average Validation Accuracy:</strong> 92%</li>
									<li><strong>Average Test Accuracy:</strong> 96%</li>
								</ul>
							</div>

						<h3 style="font-size: 1.3em; line-height: 1.4; color: #28a745; margin-top: 30px; margin-bottom: 15px;">Live Detection Performance</h3>
						<p style="font-size: 1.05em; line-height: 1.8;">In live testing on demo day with real-time video input:</p>
						<div style="background: #f0f4f8; padding: 20px; border-left: 4px solid #28a745; border-radius: 4px; margin: 20px 0;">
							<ul style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
									<li><strong>True Positive Rate:</strong> 71.4% (correctly detecting CP+)</li>
									<li><strong>True Negative Rate:</strong> 71.4% (correctly detecting normal movement)</li>
									<li><strong>Test Dataset:</strong> 42 videos (14 CP+, 28 CP-)</li>
								</ul>
							</div>

						<h3 style="font-size: 1.3em; line-height: 1.4; color: #28a745; margin-top: 30px; margin-bottom: 15px;">Extended Model Validation: Dance Recognition</h3>
						<p style="font-size: 1.05em; line-height: 1.8;">To validate that our <strong>LSTM architecture could achieve higher accuracy with more training data</strong>, we trained a secondary model on 750 videos of dance movements (Gangnam Style, Under the Sea, and no dance). This model achieved <strong>100% accuracy</strong> on diverse participants at different angles and distances (0.5-3 meters from camera)‚Äîproving that our architecture is sound and will scale with larger infant datasets.</p>
						
						<p style="font-size: 1.05em; line-height: 1.8; color: #28a745;"><strong>This finding is critical:</strong> It demonstrates our model's capacity to reach 90%+ clinical accuracy once we collect sufficient labeled infant data.</p>
						
						<h4 style="font-size: 1.3em; line-height: 1.4; color: #0056b3; margin-top: 25px; margin-bottom: 15px;">Dance Model Performance Examples</h4>							<div style="margin-top: 30px;">
								<h5 style="font-size: 1.15em; color: #1a3a52; border-bottom: 2px solid #007bff; padding-bottom: 8px; margin-bottom: 15px;">üï∫ Gangnam Style Recognition (100% Accuracy)</h5>
								<div class="row" style="display: flex; gap: 10px; margin: 15px 0; flex-wrap: wrap;">
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image26.png" alt="Gangnam style dancer 1" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 1</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image24.png" alt="Gangnam style dancer 2" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 2</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image19.png" alt="Gangnam style dancer 3" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 3</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image17.png" alt="Gangnam style dancer 4" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 4</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image1.png" alt="Gangnam style dancer 5" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 5</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image18.png" alt="Gangnam style dancer 6" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 6</figcaption>
									</figure>
								</div>
								
								<h5 style="font-size: 1.15em; color: #1a3a52; border-bottom: 2px solid #007bff; padding-bottom: 8px; margin-top: 25px; margin-bottom: 15px;">üåä Under the Sea Recognition (100% Accuracy)</h5>
								<div class="row" style="display: flex; gap: 10px; margin: 15px 0; flex-wrap: wrap;">
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image10.png" alt="Under the sea dancer 1" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 1</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image7.png" alt="Under the sea dancer 2" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 2</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image31.png" alt="Under the sea dancer 3" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Dancer 3</figcaption>
									</figure>
								</div>
								
								<h5 style="font-size: 1.15em; color: #1a3a52; border-bottom: 2px solid #007bff; padding-bottom: 8px; margin-top: 25px; margin-bottom: 15px;">üö´ No Dance (Control Group - 100% Accuracy)</h5>
								<div class="row" style="display: flex; gap: 10px; margin: 15px 0; flex-wrap: wrap;">
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image5.png" alt="No dance example 1" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Example 1</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image20.png" alt="No dance example 2" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Example 2</figcaption>
									</figure>
									<figure style="flex: 1; min-width: 150px; text-align: center;">
										<img src="images/image6.png" alt="No dance example 3" style="max-width: 100%; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);" />
										<figcaption style="font-size: 0.9em; color: #666;">Example 3</figcaption>
									</figure>
								</div>
							</div>
							
							<p style="font-size: 0.95em; color: #666; margin-top: 20px; font-style: italic;"><strong>Figure 7:</strong> Dance model validation showing 100% classification accuracy across three movement classes (Gangnam Style, Under the Sea, No Dance) with diverse participants, camera angles, and body positions.</p>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #dc3545; padding-bottom: 15px; margin-bottom: 30px;">IP Strategy & Market Position</h2>
							
						<h3 style="font-size: 1.3em; line-height: 1.4; color: #dc3545; margin-top: 30px; margin-bottom: 15px;">Competitive Landscape & Related IP</h3>
						<p style="font-size: 1.05em; line-height: 1.8;">The baby monitor market includes several existing products (<strong>BabbyCam</strong>, <strong>Nanit Pro</strong>), but <strong>none focus on developmental disease detection</strong>. The general concept of baby monitors (since 1937) has limited patent protection. We identified one active US patent (US10565846B2) for crying/sleep detection, which could limit certain feature sets in the US market.</p>
						
						<h3 style="font-size: 1.3em; line-height: 1.4; color: #dc3545; margin-top: 30px; margin-bottom: 15px;">Our IP Protection Strategy</h3>
						<p style="font-size: 1.05em; line-height: 1.8;">Our most defensible asset is <strong>proprietary data</strong>. Our multi-pronged approach includes:</p>
						<ol style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
								<li><strong>General Movement Assessment License:</strong> Obtain a license from the General Movements Trust for clinical assessment methodology</li>
								<li><strong>Patent Strategy:</strong> File dependent patent claims under existing video monitoring patents for our novel detection algorithms</li>
								<li><strong>Proprietary Datasets:</strong> Build a large proprietary dataset from customer deployments and research partnerships (e.g., Dr. Edmund Ho, UBC Hospital)</li>
								<li><strong>International Expansion:</strong> Expand to Canada, Europe, and China where US patents have limited jurisdiction</li>
							</ol>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #17a2b8; padding-bottom: 15px; margin-bottom: 30px;">Next Steps & Future Work</h2>
							
							<p style="font-size: 1.05em; line-height: 1.8;">Our development roadmap focuses on <strong>scaling the model, deploying to real-world settings, and pursuing regulatory approval</strong>. Key milestones include:</p>
							
							<ul style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
								<li><strong>Data Expansion (Q1-Q2 2024):</strong> Partner with medical institutions to collect <strong>500+ videos each</strong> of CP+ and CP- infants to reach our <strong>90% specificity/sensitivity target</strong></li>
								
								<li><strong>Free Diagnostic Web App (Q3 2024):</strong> Launch a publicly available app to gather crowdsourced infant movement data for diagnosis verification and model refinement</li>
								
								<li><strong>Hardware Deployment (Q4 2024):</strong> Deploy Jetson Nano-based prototype on cribs in clinical settings for real-world validation and pediatric feedback</li>
								
								<li><strong>FDA Approval (2025):</strong> Pursue FDA Class I clearance for commercial baby monitor launch in the United States</li>
								
								<li><strong>Model Architecture Upgrade:</strong> Transition from LSTM to <strong>Transformer architecture</strong> when computational constraints allow, enabling multi-disease detection</li>
								
								<li><strong>Feature Expansion:</strong> Extend detection to <strong>autism spectrum</strong> and <strong>infantile seizures</strong> using the same modular architecture</li>
							</ul>
						</section>

						<section>
							<h2 style="font-size: 1.8em; line-height: 1.4; color: #1a3a52; border-bottom: 3px solid #6f42c1; padding-bottom: 15px; margin-bottom: 30px;">Project Resources</h2>
							
							<h3 style="font-size: 1.3em; line-height: 1.4; color: #6f42c1; margin-top: 30px; margin-bottom: 15px;">Key Resources & Documentation</h3>
							<ul style="font-size: 1.05em; line-height: 1.8; margin-left: 20px;">
								<li><strong><a href="https://github.com/sanjanachawla/NVD" target="_blank" style="color: #007bff;">Project Repository (GitHub)</a></strong> ‚Äì Complete source code and model implementations</li>
								<li><strong>Jupyter Notebooks</strong> ‚Äì Model training, feature selection, and validation scripts</li>
								<li><strong>Labeled Infant Dataset</strong> ‚Äì Medical-grade annotated movement videos (HIPAA-compliant)</li>
								<li><strong>Jetson Nano Prototype</strong> ‚Äì Hardware configuration with IR camera and real-time inference pipeline</li>
								<li><strong>Research Partnerships</strong> ‚Äì Collaboration with Dr. Edmund Ho, UBC Hospital for clinical validation</li>
							</ul>
						</section>
					</article>

					<!-- Back Button -->
					<ul class="actions">
						<li><a href="index.html" class="button">Back to Home</a></li>
					</ul>					</div>
				</div>

				<!-- Footer -->
				<footer id="footer">
					<div class="inner">
						<section>
							<h2>Follow</h2>
							<ul class="icons">
								<li><a href="https://github.com/sanjanachawla" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="7789290247" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
								<li><a href="sanjanachawla99@gmail.com" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								<li><a href="https://www.linkedin.com/in/sanjana-chawla-2708b0210/" class="label"><span class="label">LinkedIn</span></a></li>
							</ul>
						</section>
					</div>
				</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
